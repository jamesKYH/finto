from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, Filter, FieldCondition, MatchValue
import os
import requests
import json
from typing import Annotated, List, Dict, Any, Optional
from langchain_core.runnables.config import RunnableConfig
from langgraph.prebuilt.tool_node import InjectedToolArg
from typing import Any
from sentence_transformers import SentenceTransformer
import re
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import HumanMessage, SystemMessage

QDRANT_URL = os.environ.get("QDRANT_URL", "http://localhost:6333")
COLLECTION_NAME = os.environ.get("COLLECTION_NAME", "my-collection")
EMBEDDING_MODEL = os.environ.get("EMBEDDING_MODEL", "all-MiniLM-L6-v2")

# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
model = SentenceTransformer(EMBEDDING_MODEL)
qdrant_client = QdrantClient(url=QDRANT_URL)

async def qdrant_search(
    query: str, 
    top_k: int = 5, 
    initial_k: int = 20,
    reranking_method: str = "hybrid",
    *, 
    config: Annotated[RunnableConfig, InjectedToolArg]
) -> list[dict[str, Any]]:
    """Search Qdrant with a text query and reranking.
    
    Args:
        query: The text query to search for
        top_k: The final number of results to return after reranking
        initial_k: The initial number of results to fetch for reranking
        reranking_method: The reranking method to use ('hybrid', 'tfidf')
        
    Returns:
        A list of search results
    """
    print(f"ğŸ“Œ qdrant_search í•¨ìˆ˜ í˜¸ì¶œë¨: ì¿¼ë¦¬='{query}', top_k={top_k}, initial_k={initial_k}, method={reranking_method}")
    
    try:
        # ë²•ë ¹ êµ¬ì¡° ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ (ì˜ˆ: ì œ1ì¥, ì œ1ì¡°)
        chapter_match = re.search(r'ì œ(\d+)ì¥', query)
        # 'ì œ1ì¡°'ì™€ '1ì¡°' ë‘ ê°€ì§€ íŒ¨í„´ ëª¨ë‘ ì¸ì‹
        article_match = re.search(r'(?:ì œ)?(\d+)ì¡°', query)
        
        # REST API ìš”ì²­ ì¤€ë¹„
        url = f"{QDRANT_URL}/collections/{COLLECTION_NAME}/points/search"
        
        # í•„í„° ì¡°ê±´ ì„¤ì •
        filter_conditions = None
        if chapter_match or article_match:
            must_conditions = []
            
            if chapter_match:
                chapter_no = f"ì œ{chapter_match.group(1)}ì¥"
                must_conditions.append({
                    "key": "chapter_no",
                    "match": {"value": chapter_no}
                })
                
            if article_match:
                article_no = f"ì œ{article_match.group(1)}ì¡°"
                must_conditions.append({
                    "key": "article_no",
                    "match": {"value": article_no}
                })
                
            if must_conditions:
                filter_conditions = {"must": must_conditions}
        
        # í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
        query_vector = model.encode(query).tolist()
    
        # REST API ìš”ì²­ í˜ì´ë¡œë“œ êµ¬ì„± - ì´ˆê¸° ê²€ìƒ‰ì—ì„œ ë” ë§ì€ ìˆ˜ì˜ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜´
        payload = {
            "params": {"hnsw_ef": 128, "exact": False},
            "vector": {"name": EMBEDDING_MODEL, "vector": query_vector},
            "limit": initial_k,  # ì´ˆê¸°ì— ë” ë§ì€ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ initial_k ì‚¬ìš©
            "with_payload": True,
            "with_vectors": False,
            "score_threshold": 0.0
        }
        
        # í•„í„° ì¡°ê±´ì´ ìˆìœ¼ë©´ ì¶”ê°€
        if filter_conditions:
            payload["filter"] = filter_conditions
            print(f"ğŸ“Œ Qdrant ê²€ìƒ‰ í•„í„° ì ìš©: {json.dumps(filter_conditions)}")
        
        print(f"ğŸ“Œ Qdrant API URL: {url}")
        response = requests.post(url, json=payload)
        print(f"ğŸ“Œ Qdrant API ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")
        
        if response.status_code == 200:
            data = response.json()
            if "result" in data:
                initial_results = data["result"]
                print(f"ğŸ“Œ ì´ˆê¸° ê²€ìƒ‰: {len(initial_results)}ê°œ í•­ëª© ê°€ì ¸ì˜´")
                
                # ê²°ê³¼ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ í•„í„° ì—†ì´ ë‹¤ì‹œ ê²€ìƒ‰
                if len(initial_results) < initial_k / 2 and filter_conditions:
                    print(f"ğŸ“Œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ í•„í„° ì—†ì´ ë‹¤ì‹œ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
                    payload.pop("filter", None)
                    response = requests.post(url, json=payload)
                    
                    if response.status_code == 200:
                        data = response.json()
                        if "result" in data:
                            initial_results = data["result"]
                            print(f"ğŸ“Œ í•„í„° ì—†ëŠ” ì´ˆê¸° ê²€ìƒ‰: {len(initial_results)}ê°œ í•­ëª© ê°€ì ¸ì˜´")
                
                # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì˜¤ë¥˜ ë°˜í™˜
                if not initial_results:
                    return [{"error": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."}]
                
                # ë¦¬ë­í‚¹ ì§„í–‰
                if reranking_method == "tfidf":
                    reranked_results = rerank_with_tfidf(query, initial_results, top_k)
                    print(f"ğŸ“Œ TF-IDF ë¦¬ë­í‚¹ ì™„ë£Œ: {len(reranked_results)}ê°œ ê²°ê³¼")
                else:  # hybrid ë°©ì‹ ì‚¬ìš©
                    reranked_results = rerank_with_hybrid(query, initial_results, top_k)
                    print(f"ğŸ“Œ í•˜ì´ë¸Œë¦¬ë“œ ë¦¬ë­í‚¹ ì™„ë£Œ: {len(reranked_results)}ê°œ ê²°ê³¼")
                
                # í˜ì´ë¡œë“œë§Œ ë°˜í™˜
                return [result["payload"] for result in reranked_results]
            else:
                print(f"ğŸ“Œ Qdrant ê²€ìƒ‰ ì˜¤ë¥˜: ê²°ê³¼ì— ë°ì´í„°ê°€ ì—†ìŒ - {response.text}")
                return [{"error": f"ê²€ìƒ‰ ê²°ê³¼ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {response.text}"}]
        else:
            print(f"ğŸ“Œ Qdrant ê²€ìƒ‰ ì˜¤ë¥˜: API ì‘ë‹µ ì‹¤íŒ¨ - {response.status_code} - {response.text}")
            return [{"error": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {response.text}"}]
    except Exception as e:
        print(f"ğŸ“Œ Qdrant ê²€ìƒ‰ ì˜ˆì™¸: {str(e)}")
        import traceback
        print(f"ğŸ“Œ ì˜ˆì™¸ ìƒì„¸ ì •ë³´: {traceback.format_exc()}")
        return [{"error": f"ê²€ìƒ‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}"}]

def rerank_with_tfidf(query, results, top_n=5):
    """TF-IDF ê¸°ë°˜ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì¬ë­í‚¹í•©ë‹ˆë‹¤."""
    # ê²°ê³¼ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if len(results) <= top_n:
        return results
    
    # ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    texts = [result["payload"].get("cleaned_content", "") for result in results]
    
    # ì¿¼ë¦¬ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ TF-IDF ë³€í™˜
    tfidf = TfidfVectorizer().fit_transform(texts + [query])
    
    # ë§ˆì§€ë§‰ ë²¡í„°(ì¿¼ë¦¬)ì™€ ë‹¤ë¥¸ ëª¨ë“  í…ìŠ¤íŠ¸ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°
    similarities = cosine_similarity(tfidf[-1:], tfidf[:-1])[0]
    
    # ìœ ì‚¬ë„ì— ë”°ë¼ ì •ë ¬
    reranked_indices = similarities.argsort()[::-1][:top_n]
    
    print(f"ğŸ“Œ TF-IDF ë¦¬ë­í‚¹ ìƒìœ„ ì ìˆ˜: {[similarities[i] for i in reranked_indices[:3]]}")
    
    return [results[i] for i in reranked_indices]

def rerank_with_hybrid(query, results, top_n=5, alpha=0.6):
    """ë²¡í„° ê²€ìƒ‰ ì ìˆ˜ì™€ TF-IDF ì ìˆ˜ë¥¼ ì¡°í•©í•˜ì—¬ í•˜ì´ë¸Œë¦¬ë“œ ì¬ë­í‚¹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    # ê²°ê³¼ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if len(results) <= top_n:
        return results
    
    # ë²¡í„° ê²€ìƒ‰ ì ìˆ˜ ì •ê·œí™”
    vector_scores = np.array([result["score"] for result in results])
    if vector_scores.max() != vector_scores.min():  # ë¶„ëª¨ê°€ 0ì´ ë˜ì§€ ì•Šë„ë¡ ì²´í¬
        vector_scores = (vector_scores - vector_scores.min()) / (vector_scores.max() - vector_scores.min())
    else:
        vector_scores = np.ones_like(vector_scores)
    
    # í…ìŠ¤íŠ¸ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
    texts = [result["payload"].get("cleaned_content", "") for result in results]
    
    try:
        tfidf = TfidfVectorizer().fit_transform(texts + [query])
        tfidf_scores = cosine_similarity(tfidf[-1:], tfidf[:-1])[0]
        
        if tfidf_scores.max() != tfidf_scores.min():  # ë¶„ëª¨ê°€ 0ì´ ë˜ì§€ ì•Šë„ë¡ ì²´í¬
            tfidf_scores = (tfidf_scores - tfidf_scores.min()) / (tfidf_scores.max() - tfidf_scores.min())
        else:
            tfidf_scores = np.ones_like(tfidf_scores)
        
        # ì ìˆ˜ ì¡°í•©
        combined_scores = alpha * vector_scores + (1 - alpha) * tfidf_scores
    except Exception as e:
        print(f"ğŸ“Œ TF-IDF ê³„ì‚° ì¤‘ ì˜¤ë¥˜, ë²¡í„° ì ìˆ˜ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤: {str(e)}")
        combined_scores = vector_scores
    
    # ì¡°í•©ëœ ì ìˆ˜ë¡œ ì •ë ¬
    reranked_indices = combined_scores.argsort()[::-1][:top_n]
    
    print(f"ğŸ“Œ í•˜ì´ë¸Œë¦¬ë“œ ë¦¬ë­í‚¹ ìƒìœ„ ì ìˆ˜: {[combined_scores[i] for i in reranked_indices[:3]]}")
    
    return [results[i] for i in reranked_indices]

async def restructure_query_with_llm(query: str) -> str:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ë²•ë¥  ê²€ìƒ‰ì— ìµœì í™”ëœ í˜•íƒœë¡œ ì§ˆë¬¸ì„ ì¬êµ¬ì„±í•©ë‹ˆë‹¤."""
    model = ChatAnthropic(
        model="claude-3-5-haiku-20241022",
        temperature=0.0,
        max_tokens=1000
    )
    
    system_prompt = """ë‹¹ì‹ ì€ ë²•ë¥  ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë²•ë¥  ê²€ìƒ‰ì— ìµœì í™”ëœ í˜•íƒœë¡œ ì¬êµ¬ì„±í•´ì£¼ì„¸ìš”.
    ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•˜ì—¬ ì¬êµ¬ì„±í•´ì£¼ì„¸ìš”:
    1. ë²•ë¥  ìš©ì–´ë¥¼ ì •í™•í•˜ê²Œ ì‚¬ìš©
    2. ë²•ë¥  ë¬¸ì„œ êµ¬ì¡°ë¥¼ ê³ ë ¤ (ì¡°, ì¥, ì ˆ ë“±)
    3. ê²€ìƒ‰ ì˜ë„ë¥¼ ëª…í™•íˆ í‘œí˜„
    4. ê´€ë ¨ ë²•ë¥  ë¶„ì•¼ë¥¼ ëª…ì‹œ
    5. êµ¬ì²´ì ì¸ ë²•ë¥  ê°œë…ì„ í¬í•¨
    
    ì¬êµ¬ì„±ëœ ì§ˆë¬¸ì€ ê²€ìƒ‰ì— ìµœì í™”ë˜ì–´ì•¼ í•˜ë©°, ì›ë˜ ì˜ë„ë¥¼ ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤."""
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=f"ì›ë³¸ ì§ˆë¬¸: {query}\n\nì¬êµ¬ì„±ëœ ì§ˆë¬¸:")
    ]
    
    response = await model.ainvoke(messages)
    return response.content.strip()

async def qdrant_search_reranked(
    query: str,
    top_k: int = 5,
    initial_k: int = 20,
    reranking_method: str = "hybrid",
    *, 
    config: Annotated[RunnableConfig, InjectedToolArg]
) -> List[Dict[str, Any]]:
    """ë²•ë¥  ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³  ê²°ê³¼ë¥¼ ë¦¬ë­í‚¹í•©ë‹ˆë‹¤."""
    try:
        # 1. LLMì„ í†µí•œ ì§ˆë¬¸ ì¬êµ¬ì„±
        restructured_query = await restructure_query_with_llm(query)
        print(f"ì›ë³¸ ì§ˆë¬¸: {query}")
        print(f"ì¬êµ¬ì„±ëœ ì§ˆë¬¸: {restructured_query}")
        
        # 2. ë²¡í„° ê²€ìƒ‰
        query_vector = model.encode(restructured_query).tolist()
        payload = {
            "vector": {"name": EMBEDDING_MODEL, "vector": query_vector},
            "limit": initial_k
        }
        
        # 3. ê²€ìƒ‰ ì‹¤í–‰
        results = await qdrant_search(restructured_query, top_k, initial_k, reranking_method, config=config)
        
        # 4. ë¦¬ë­í‚¹
        if reranking_method == "hybrid":
            reranked_results = rerank_with_hybrid(restructured_query, results, top_k)
        else:
            reranked_results = rerank_with_tfidf(restructured_query, results, top_k)
            
        return reranked_results
        
    except Exception as e:
        print(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return []

"""This module provides tools for vector search and reranking functionality.

These tools are specialized for legal document search with vector and hybrid reranking capabilities.
"""

from typing import Any, Callable, List, Optional, cast
from langchain_core.runnables import RunnableConfig
from langchain_core.tools import InjectedToolArg
from typing_extensions import Annotated

from react_agent.configuration import Configuration

TOOLS: List[Callable[..., Any]] = [qdrant_search_reranked]
