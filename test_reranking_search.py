from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue, models
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ì—°ê²° ì„¤ì •
QDRANT_URL = "http://localhost:6333"
COLLECTION_NAME = "my-collection"
EMBEDDING_MODEL = "all-MiniLM-L6-v2"

# í´ë¼ì´ì–¸íŠ¸ ë° ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
client = QdrantClient(url=QDRANT_URL)
model = SentenceTransformer(EMBEDDING_MODEL)

def search_with_filter(query, filter_dict=None, top_k=20):
    """
    í•„í„°ë¥¼ ì ìš©í•˜ì—¬ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰í•  í…ìŠ¤íŠ¸
        filter_dict: í•„í„° ì¡°ê±´ ë”•ì…”ë„ˆë¦¬
        top_k: ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜ (ê¸°ë³¸ê°’ 20ìœ¼ë¡œ ì¦ê°€)
    """
    query_vector = model.encode(query).tolist()
    filter_obj = None
    
    if filter_dict:
        must_conditions = []
        for key, value in filter_dict.items():
            must_conditions.append(
                models.FieldCondition(
                    key=key,
                    match=models.MatchValue(value=value)
                )
            )
        filter_obj = models.Filter(must=must_conditions)
    
    # Qdrant API í˜¸ì¶œ
    search_results = client.search(
        collection_name=COLLECTION_NAME,
        query_vector=(EMBEDDING_MODEL, query_vector),
        limit=top_k,
        query_filter=filter_obj,
        with_payload=True
    )
    
    return search_results

def rerank_with_tfidf(query, results, top_n=5):
    """
    TF-IDF ê¸°ë°˜ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì¬ë­í‚¹í•©ë‹ˆë‹¤.
    
    Args:
        query: ì›ë³¸ ê²€ìƒ‰ ì¿¼ë¦¬
        results: Qdrant ê²€ìƒ‰ ê²°ê³¼
        top_n: ìµœì¢…ì ìœ¼ë¡œ ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
    """
    # ê²°ê³¼ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if len(results) <= top_n:
        return results
    
    # ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    texts = [result.payload.get("cleaned_content", "") for result in results]
    
    # ì¿¼ë¦¬ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ TF-IDF ë³€í™˜
    tfidf = TfidfVectorizer().fit_transform(texts + [query])
    
    # ë§ˆì§€ë§‰ ë²¡í„°(ì¿¼ë¦¬)ì™€ ë‹¤ë¥¸ ëª¨ë“  í…ìŠ¤íŠ¸ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°
    similarities = cosine_similarity(tfidf[-1:], tfidf[:-1])[0]
    
    # ìœ ì‚¬ë„ì— ë”°ë¼ ì •ë ¬
    reranked_indices = similarities.argsort()[::-1][:top_n]
    
    return [results[i] for i in reranked_indices]

def rerank_with_hybrid(query, results, top_n=5, alpha=0.7):
    """
    ë²¡í„° ê²€ìƒ‰ ì ìˆ˜ì™€ TF-IDF ì ìˆ˜ë¥¼ ì¡°í•©í•˜ì—¬ í•˜ì´ë¸Œë¦¬ë“œ ì¬ë­í‚¹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ì›ë³¸ ê²€ìƒ‰ ì¿¼ë¦¬
        results: Qdrant ê²€ìƒ‰ ê²°ê³¼
        top_n: ìµœì¢…ì ìœ¼ë¡œ ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
        alpha: ë²¡í„° ê²€ìƒ‰ ì ìˆ˜ì˜ ê°€ì¤‘ì¹˜ (0~1), 1-alphaëŠ” TF-IDF ì ìˆ˜ì˜ ê°€ì¤‘ì¹˜
    """
    # ê²°ê³¼ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if len(results) <= top_n:
        return results
    
    # ë²¡í„° ê²€ìƒ‰ ì ìˆ˜ ì •ê·œí™”
    vector_scores = np.array([result.score for result in results])
    vector_scores = (vector_scores - vector_scores.min()) / (vector_scores.max() - vector_scores.min() + 1e-8)
    
    # í…ìŠ¤íŠ¸ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
    texts = [result.payload.get("cleaned_content", "") for result in results]
    tfidf = TfidfVectorizer().fit_transform(texts + [query])
    tfidf_scores = cosine_similarity(tfidf[-1:], tfidf[:-1])[0]
    tfidf_scores = (tfidf_scores - tfidf_scores.min()) / (tfidf_scores.max() - tfidf_scores.min() + 1e-8)
    
    # ì ìˆ˜ ì¡°í•©
    combined_scores = alpha * vector_scores + (1 - alpha) * tfidf_scores
    
    # ì¡°í•©ëœ ì ìˆ˜ë¡œ ì •ë ¬
    reranked_indices = combined_scores.argsort()[::-1][:top_n]
    
    return [results[i] for i in reranked_indices]

def search_with_reranking(query, filter_dict=None, final_top_k=5, reranking_method="hybrid"):
    """
    ë‘ ë‹¨ê³„ ê²€ìƒ‰: ìš°ì„  ë§ì€ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¨ í›„ ì¬ë­í‚¹í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        filter_dict: í•„í„° ì¡°ê±´
        final_top_k: ìµœì¢…ì ìœ¼ë¡œ ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
        reranking_method: ì¬ë­í‚¹ ë°©ë²• ('tfidf' ë˜ëŠ” 'hybrid')
    """
    # ì²« ë²ˆì§¸ ë‹¨ê³„: ì¶©ë¶„í•œ ìˆ˜ì˜ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜´ (final_top_kì˜ 4ë°°)
    initial_top_k = final_top_k * 4
    initial_results = search_with_filter(query, filter_dict, top_k=initial_top_k)
    
    print(f"ì²« ë²ˆì§¸ ê²€ìƒ‰ ë‹¨ê³„: {len(initial_results)}ê°œ í•­ëª© ì°¾ìŒ")
    
    # ë‘ ë²ˆì§¸ ë‹¨ê³„: ì¬ë­í‚¹
    if reranking_method == "tfidf":
        reranked_results = rerank_with_tfidf(query, initial_results, final_top_k)
    else:  # hybrid ë°©ì‹ì´ ê¸°ë³¸
        reranked_results = rerank_with_hybrid(query, initial_results, final_top_k)
    
    return reranked_results

def print_results(results, title):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("=" * 80)
    print(f"ğŸ” {title} (ì´ {len(results)}ê°œ)")
    print("=" * 80)
    
    for i, result in enumerate(results):
        payload = result.payload
        
        # ë©”íƒ€ë°ì´í„° ì ‘ê·¼
        chapter_no = payload.get("chapter_no", "ì¥ ì •ë³´ ì—†ìŒ")
        chapter_title = payload.get("chapter_title", "")
        article_no = payload.get("article_no", "ì¡° ì •ë³´ ì—†ìŒ")
        article_title = payload.get("article_title", "")
        item_no = payload.get("item_no", "")
        
        content = payload.get("cleaned_content", "ë‚´ìš© ì—†ìŒ")
        
        print(f"{i+1}. {chapter_no} {chapter_title} > {article_no} {article_title} {item_no}")
        print(f"   ì ìˆ˜: {result.score:.4f}")
        print(f"   ID: {payload.get('id', 'ID ì—†ìŒ')}")
        print(f"   ë‚´ìš©: {content[:150]}...")
        print()

print("ë¦¬ë­í‚¹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

# í…ŒìŠ¤íŠ¸ 1: ì¼ë°˜ ê²€ìƒ‰ vs ë¦¬ë­í‚¹ ê²€ìƒ‰ (ì œ1ì¥)
print("\n*** í…ŒìŠ¤íŠ¸ 1: ì¼ë°˜ ê²€ìƒ‰ vs ë¦¬ë­í‚¹ ê²€ìƒ‰ (ì œ1ì¥) ***")
regular_results = search_with_filter("ì™¸êµ­í™˜ê±°ë˜ë²• ì œ1ì¥", {"chapter_no": "ì œ1ì¥"}, top_k=5)
print_results(regular_results, "ì¼ë°˜ ê²€ìƒ‰ ê²°ê³¼ (ì œ1ì¥)")

reranked_results = search_with_reranking("ì™¸êµ­í™˜ê±°ë˜ë²• ì œ1ì¥", {"chapter_no": "ì œ1ì¥"}, final_top_k=5)
print_results(reranked_results, "ë¦¬ë­í‚¹ ê²€ìƒ‰ ê²°ê³¼ (ì œ1ì¥)")

# í…ŒìŠ¤íŠ¸ 2: ì œ1ì¡° ëª©ì  ê²€ìƒ‰
print("\n*** í…ŒìŠ¤íŠ¸ 2: ì œ1ì¡° ëª©ì  ê²€ìƒ‰ ***")
regular_results = search_with_filter("ì™¸êµ­í™˜ê±°ë˜ë²• ì œ1ì¡° ëª©ì ", {"article_no": "ì œ1ì¡°"}, top_k=3)
print_results(regular_results, "ì¼ë°˜ ê²€ìƒ‰ ê²°ê³¼ (ì œ1ì¡° ëª©ì )")

reranked_results = search_with_reranking("ì™¸êµ­í™˜ê±°ë˜ë²• ì œ1ì¡° ëª©ì ", {"article_no": "ì œ1ì¡°"}, final_top_k=3)
print_results(reranked_results, "ë¦¬ë­í‚¹ ê²€ìƒ‰ ê²°ê³¼ (ì œ1ì¡° ëª©ì )")

# í…ŒìŠ¤íŠ¸ 3: í•„í„° ì—†ëŠ” ê²€ìƒ‰ - í•´ì™¸ì†¡ê¸ˆ ê·œì •
print("\n*** í…ŒìŠ¤íŠ¸ 3: í•„í„° ì—†ëŠ” ê²€ìƒ‰ - í•´ì™¸ì†¡ê¸ˆ ê·œì • ***")
regular_results = search_with_filter("ì™¸êµ­í™˜ê±°ë˜ë²• í•´ì™¸ì†¡ê¸ˆ ì‹ ê³  ì˜ë¬´", None, top_k=5)
print_results(regular_results, "ì¼ë°˜ ê²€ìƒ‰ ê²°ê³¼ (í•´ì™¸ì†¡ê¸ˆ ì‹ ê³  ì˜ë¬´)")

reranked_results = search_with_reranking("ì™¸êµ­í™˜ê±°ë˜ë²• í•´ì™¸ì†¡ê¸ˆ ì‹ ê³  ì˜ë¬´", None, final_top_k=5)
print_results(reranked_results, "ë¦¬ë­í‚¹ ê²€ìƒ‰ ê²°ê³¼ (í•´ì™¸ì†¡ê¸ˆ ì‹ ê³  ì˜ë¬´)")

# í…ŒìŠ¤íŠ¸ 4: TF-IDF ê¸°ë°˜ ë¦¬ë­í‚¹ vs í•˜ì´ë¸Œë¦¬ë“œ ë¦¬ë­í‚¹
print("\n*** í…ŒìŠ¤íŠ¸ 4: TF-IDF vs í•˜ì´ë¸Œë¦¬ë“œ ë¦¬ë­í‚¹ ***")
tfidf_results = search_with_reranking("ì™¸êµ­í™˜ê±°ë˜ë²• ìê¸ˆì„¸íƒë°©ì§€", None, final_top_k=5, reranking_method="tfidf")
print_results(tfidf_results, "TF-IDF ë¦¬ë­í‚¹ ê²°ê³¼ (ìê¸ˆì„¸íƒë°©ì§€)")

hybrid_results = search_with_reranking("ì™¸êµ­í™˜ê±°ë˜ë²• ìê¸ˆì„¸íƒë°©ì§€", None, final_top_k=5, reranking_method="hybrid")
print_results(hybrid_results, "í•˜ì´ë¸Œë¦¬ë“œ ë¦¬ë­í‚¹ ê²°ê³¼ (ìê¸ˆì„¸íƒë°©ì§€)") 